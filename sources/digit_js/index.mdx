export const metadata = {
  title: "Digit.js",
  date: "2022-10-05",
  tag: "SelfDirected, OnGoing",
};

<とりあえず書き殴り。後で推敲。22/10/10>

「動き」をたよりに操作するコントローラーの研究。コントローラーを設計する思想として、一つには「記号」をたよりとしたインターフェースが考えられる。例えば、上下左右を示すボタン、連続値を制御するスライダーといったものである。記号をたよりにしたコントローラーは、「動かす前に」その挙動についての推論ができ、スムーズに操作できる。こうした記号をあえて、「動かすまえにわかるエレメント」と表現してみる。「理解する」ことと「操作する」ことは完全に独立したものとして設計可能なコントローラーである。しかし私が設計したいのは、こうした「記号」で構成されたコントローラーではない。インターフェースとしては、実際に触ってみるより前の時点で動作について「わかる」記号は用意されていない。ガチャガチャと動かしてみて、行為と結果とのインタラクションを通して初めて理解し、操作できるようになる、別の言い方をすれば「非言語的なやりとり」で操作可能になるコントローラーを構想する。そのための、「動かすことでわかるエレメント」を見つけ出すのが研究の目的。

先述の、「動かすことでわかる」とはどういう状態のことを指すのか。渡邊（2013）らによる研究では、複数のダミーカーソルの中に自分自身のカーソルを混在させ、操作者がそこからマウスを動かすことによって自己を発見する体験をもたらすインターフェースが提示された。同時にこのインターフェースは、操作者はマウスを動かすことによって自己を発見できる一方で、観察者には発見できないという非対称性についての言及がある。このことはまさに、上記の「実際に触ってみるより前の時点で動作について「わかる」記号は用意されて」おらず、「ガチャガチャと動かしてみて、行為と結果とのインタラクションを通して初めて理解」する過程を表している。また、私が以前制作し、展示を行った「Digitalize」もまさに「動かすことでわかる」インターフェースになっている。

なぜ「動かすことでわかる」コントローラーの設計を目指すのか。これは完成したあとになってから初めて記述できる部分も多分にあるものだが、一つの可能性として「記号的な枠組みで設計されたコントローラーでは操作できなかった操作対象」を操作可能にするのではないかと考えている。記号的な枠組みによる操作感というのは、挙動と入力を一対一に対応づけられるように因数分解する必要があり、それを操作するユーザは分解され、独立した要素を個々に制御することが求められる。しかし、「非言語的なやりとり」はそうした因数分解のロジックを超えた、融合的、包括的な操作を可能にするのではないかということを考えている。

### Links

[渡邊恵太, 樋口文人, 稲見昌彦, 五十嵐健夫, "複数ダミーカーソル中における自分自身のカーソル特定", 情報処理学会 インタラクション 2013, p.25-p.31](http://www.interaction-ipsj.org/archives/paper2013/data/Interaction2013/oral/data/pdf/13INT004.pdf)
[Digitalize, IAMAS OpenHouse 2022](https://k1105.github.io/eee_openhouse_2022/)
